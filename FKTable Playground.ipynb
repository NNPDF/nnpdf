{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cceb1080",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from validphys.loader import _get_nnpdf_profile\n",
    "from validphys.api import API\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from validphys.convolution import central_predictions\n",
    "\n",
    "profile = _get_nnpdf_profile()\n",
    "yaml_db = Path(profile[\"data_path\"]) / \"yamldb\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1eb8f3",
   "metadata": {},
   "source": [
    "The `yaml_db` folder is a temporary thing as it contains files that look like:\n",
    "\n",
    "```yaml\n",
    "conversion_factor: 1.0\n",
    "operands:\n",
    "- - NMC_NC_EM_D_F2\n",
    "- - NMC_NC_EM_P_F2\n",
    "operation: RATIO\n",
    "target_dataset: NMCPD\n",
    "```\n",
    "\n",
    "This information will eventually be part of the new commondata format of course.\n",
    "\n",
    "The `operation` is applied to the first level of the list while the second level is just concatenated. This is necessary since `pineappl` fktables might contain one layer of concatenation which is already done for the \"classic\" fktables.\n",
    "\n",
    "The `pineappl` fktables will live inside the appropiate `theory_xxx` folder `/pineappls`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "051581e1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LHAPDF 6.4.0 loading /usr/share/lhapdf/LHAPDF/NNPDF40_nnlo_as_01180/NNPDF40_nnlo_as_01180_0000.dat\n",
      "NNPDF40_nnlo_as_01180 PDF set, member #0, version 1\n"
     ]
    }
   ],
   "source": [
    "# Test them all\n",
    "if True:\n",
    "    from yaml import safe_load\n",
    "    pdf = API.pdf(pdf=\"NNPDF40_nnlo_as_01180\")\n",
    "    all_res = []\n",
    "    #nnpdf40_runcard = safe_load(Path(\"/home/juacrumar/NNPDF-testing/nnpdf/n3fit/NNPDF40_with_pineappl.yml\").read_text())\n",
    "    nnpdf40_runcard = safe_load(Path(\"/mount/storage/Academic_Workspace/NNPDF/source/nnpdf/n3fit/NNPDF40_with_pineappl.yml\").read_text())\n",
    "    for d in nnpdf40_runcard[\"dataset_inputs\"]:\n",
    "        target_ds = d[\"dataset\"]\n",
    "        cfac = d.get(\"cfac\", [])\n",
    "        old_ds = API.dataset(dataset_input={\"dataset\": target_ds, \"cfac\": cfac + [\"oldmode\"]}, theoryid=200, use_cuts=\"internal\")\n",
    "        ds = API.dataset(dataset_input={\"dataset\": target_ds, \"cfac\": cfac}, theoryid=200, use_cuts=\"internal\")\n",
    "        new_cp = central_predictions(ds, pdf)\n",
    "        cp = central_predictions(old_ds, pdf)\n",
    "        all_res.append(pd.concat([new_cp, cp, new_cp/cp], axis=1, keys=[\"vp\", \"pine\", f\"ratio {target_ds}, {cfac}\"]))\n",
    "        \n",
    "    for i in all_res:\n",
    "        mean_ratio = i[i.columns[2]].mean()\n",
    "        if not (0.9 < mean_ratio < 1.1):\n",
    "            print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4d88771",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_ds = \"CMS_TTBAR_2D_DIFF_MTT_TRAP_NORM\"\n",
    "cfac = [\"QCD\"] # [\"NRM\"]\n",
    "old_ds = API.dataset(dataset_input={\"dataset\": target_ds, \"cfac\": cfac + [\"oldmode\"]}, theoryid=200, use_cuts=\"internal\")\n",
    "ds = API.dataset(dataset_input={\"dataset\": target_ds, \"cfac\": cfac}, theoryid=200, use_cuts=\"internal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "316a571e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LHAPDF 6.4.0 loading /usr/share/lhapdf/LHAPDF/NNPDF40_nnlo_as_01180/NNPDF40_nnlo_as_01180_0000.dat\n",
      "NNPDF40_nnlo_as_01180 PDF set, member #0, version 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>pine</th>\n",
       "      <th>vp</th>\n",
       "      <th>ratio vp/ratio</th>\n",
       "      <th>ratio pine/vp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.003383</td>\n",
       "      <td>0.003382</td>\n",
       "      <td>0.999938</td>\n",
       "      <td>1.000062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.003004</td>\n",
       "      <td>0.002982</td>\n",
       "      <td>0.992669</td>\n",
       "      <td>1.007385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002128</td>\n",
       "      <td>0.002114</td>\n",
       "      <td>0.993233</td>\n",
       "      <td>1.006813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000740</td>\n",
       "      <td>0.000741</td>\n",
       "      <td>1.001264</td>\n",
       "      <td>0.998738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002754</td>\n",
       "      <td>0.002664</td>\n",
       "      <td>0.967190</td>\n",
       "      <td>1.033923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.002355</td>\n",
       "      <td>0.002363</td>\n",
       "      <td>1.003314</td>\n",
       "      <td>0.996697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.001637</td>\n",
       "      <td>0.001637</td>\n",
       "      <td>0.999900</td>\n",
       "      <td>1.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000580</td>\n",
       "      <td>0.000578</td>\n",
       "      <td>0.995907</td>\n",
       "      <td>1.004110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.001080</td>\n",
       "      <td>0.001038</td>\n",
       "      <td>0.960902</td>\n",
       "      <td>1.040689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000927</td>\n",
       "      <td>0.000930</td>\n",
       "      <td>1.003073</td>\n",
       "      <td>0.996936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000675</td>\n",
       "      <td>0.000678</td>\n",
       "      <td>1.004371</td>\n",
       "      <td>0.995648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000274</td>\n",
       "      <td>0.000276</td>\n",
       "      <td>1.005711</td>\n",
       "      <td>0.994321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.895151</td>\n",
       "      <td>1.117130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>1.000492</td>\n",
       "      <td>0.999508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.996513</td>\n",
       "      <td>1.003499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>1.006510</td>\n",
       "      <td>0.993532</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          pine        vp ratio vp/ratio ratio pine/vp\n",
       "             0         0              0             0\n",
       "data                                                 \n",
       "0     0.003383  0.003382       0.999938      1.000062\n",
       "1     0.003004  0.002982       0.992669      1.007385\n",
       "2     0.002128  0.002114       0.993233      1.006813\n",
       "3     0.000740  0.000741       1.001264      0.998738\n",
       "4     0.002754  0.002664       0.967190      1.033923\n",
       "5     0.002355  0.002363       1.003314      0.996697\n",
       "6     0.001637  0.001637       0.999900      1.000100\n",
       "7     0.000580  0.000578       0.995907      1.004110\n",
       "8     0.001080  0.001038       0.960902      1.040689\n",
       "9     0.000927  0.000930       1.003073      0.996936\n",
       "10    0.000675  0.000678       1.004371      0.995648\n",
       "11    0.000274  0.000276       1.005711      0.994321\n",
       "12    0.000078  0.000069       0.895151      1.117130\n",
       "13    0.000069  0.000069       1.000492      0.999508\n",
       "14    0.000064  0.000064       0.996513      1.003499\n",
       "15    0.000034  0.000035       1.006510      0.993532"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's try to get a prediction out of it\n",
    "pdf = API.pdf(pdf=\"NNPDF40_nnlo_as_01180\")\n",
    "new_cp = central_predictions(ds, pdf)\n",
    "cp = central_predictions(old_ds, pdf)\n",
    "pd.concat([new_cp, cp, cp/new_cp, new_cp/cp], axis=1, keys=[\"pine\", \"vp\", \"ratio vp/ratio\", \"ratio pine/vp\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0905d0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pine_fkspec = ds.fkspecs[0]\n",
    "old_fkspec = old_ds.fkspecs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acd19243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LHAPDF 6.4.0 loading all 101 PDFs in set NNPDF40_nnlo_as_01180\n",
      "NNPDF40_nnlo_as_01180, version 1; 101 PDF members\n",
      "[0.5982222  0.53206434 0.37638204 0.13101867 0.59686953 0.51087613\n",
      " 0.35425162 0.12440635 0.23262168 0.1988827  0.14422644 0.05755101\n",
      " 0.01654738 0.01469668 0.01335605 0.00692297]\n"
     ]
    }
   ],
   "source": [
    "import pineappl\n",
    "pines = [pineappl.fk_table.FkTable.read(i.as_posix()) for i in pine_fkspec.fkpath]\n",
    "# Inspect the pineappl prediction\n",
    "res_pine = []\n",
    "pp = pines[0]\n",
    "lpdf = pdf.load()\n",
    "\n",
    "for p in pines:\n",
    "    res_pine.append(p.convolute_with_one(2212, lpdf.central_member.xfxQ2))\n",
    "total_pine = np.concatenate(res_pine)\n",
    "print(total_pine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3a77d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's inspect the content of the old fktables, remove the cfactor for now\n",
    "from validphys.fkparser import load_fktable\n",
    "old_fkspec.cfactors = False\n",
    "old_fktabledata = load_fktable(old_fkspec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ab604e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hadronic?: True\n",
      "Q: 1.65\n",
      "n: 16\n",
      "xgrid shape: (40,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"hadronic?: {old_fktabledata.hadronic}\")\n",
    "print(f\"Q: {old_fktabledata.Q0}\")\n",
    "print(f\"n: {old_fktabledata.ndata}\")\n",
    "print(f\"xgrid shape: {old_fktabledata.xgrid.shape}\")\n",
    "#old_fktabledata.sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62709983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First read the metadata that vp `FKTableData` needs and that all subgrids share\n",
    "Q0 = np.sqrt(pp.muf2())\n",
    "xgrid = pp.x_grid()\n",
    "# Hadronic means in practice that not all luminosity combinations are just electron X proton\n",
    "hadronic = not all(-11 in i for i in pp.lumi())\n",
    "# Now prepare the concatenation of grids\n",
    "fktables = []\n",
    "for p in pines:\n",
    "    tmp = p.table().T/p.bin_normalizations()\n",
    "    fktables.append(tmp.T)\n",
    "fktable = np.concatenate(fktables, axis=0)\n",
    "ndata = fktable.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9d5a130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(100, 21),\n",
       " (100, 203),\n",
       " (100, 208),\n",
       " (100, 200),\n",
       " (100, 103),\n",
       " (100, 108),\n",
       " (100, 115),\n",
       " (21, 21),\n",
       " (21, 203),\n",
       " (21, 208),\n",
       " (21, 200),\n",
       " (21, 103),\n",
       " (21, 108),\n",
       " (21, 115),\n",
       " (21, 100),\n",
       " (200, 203),\n",
       " (200, 208),\n",
       " (203, 203),\n",
       " (203, 208),\n",
       " (203, 200),\n",
       " (203, 103),\n",
       " (203, 108),\n",
       " (203, 115),\n",
       " (203, 100),\n",
       " (208, 208),\n",
       " (208, 200),\n",
       " (208, 103),\n",
       " (208, 108),\n",
       " (208, 115),\n",
       " (208, 100),\n",
       " (200, 200),\n",
       " (200, 103),\n",
       " (200, 108),\n",
       " (200, 115),\n",
       " (200, 100),\n",
       " (103, 103),\n",
       " (103, 108),\n",
       " (103, 115),\n",
       " (103, 100),\n",
       " (108, 108),\n",
       " (108, 115),\n",
       " (108, 100),\n",
       " (115, 115),\n",
       " (115, 100),\n",
       " (100, 100)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp.lumi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b95c8549",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mcolumns\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99782f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's try to join the fktable, luminosity and xgrid into a pandas dataframe\n",
    "# keeping compatibility with validphys and, hopefully, 50% of my own sanity\n",
    "\n",
    "# Step 1), make the luminosity into a 14x14 mask for the evolution basis\n",
    "eko_numbering_scheme = (22, 100, 21, 200, 203, 208, 215, 224, 235, 103, 108, 115, 124, 135)\n",
    "# note that this is the same ordering that was used in fktables\n",
    "co = []\n",
    "for i, j in pp.lumi():\n",
    "    # Ask where this would fall in a 14x14 matrix\n",
    "    idx = eko_numbering_scheme.index(i)\n",
    "    jdx = eko_numbering_scheme.index(j)\n",
    "    co.append(idx*14 + jdx)\n",
    "    \n",
    "# Step 2) prepare the indices for the dataframe\n",
    "xi = np.arange(len(xgrid))\n",
    "ni = np.arange(ndata)\n",
    "mi = pd.MultiIndex.from_product([ni, xi, xi], names=[\"data\", \"x1\", \"x2\"])\n",
    "\n",
    "# Step 3) Now play with the array until we flatten it in the right way?\n",
    "# The fktables for pineappl have this extra factor of x...\n",
    "# The output of pineappl is (ndata, flavours, x, x)\n",
    "lf = len(co)\n",
    "xfktable = fktable.reshape(ndata, lf, -1)/(xgrid[:,None]*xgrid[None,:]).flatten()\n",
    "fkmod = np.moveaxis(xfktable, 1, -1)\n",
    "fkframe = fkmod.reshape(-1, lf)\n",
    "\n",
    "# Uff, big\n",
    "df = pd.DataFrame(fkframe, index=mi, columns=co)\n",
    "\n",
    "from validphys.convolution import central_hadron_predictions\n",
    "from validphys.coredata import FKTableData\n",
    "fk = FKTableData(sigma=df, ndata=ndata,  Q0=Q0, metadata=None, hadronic=True, xgrid=xgrid)\n",
    "central_hadron_predictions(fk, pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e323f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a luminosity tensor and check that the results are correct\n",
    "from validphys.pdfbases import evolution\n",
    "\n",
    "evol_basis = (\n",
    "    \"photon\",\n",
    "    \"singlet\",\n",
    "    \"g\",\n",
    "    \"V\",\n",
    "    \"V3\",\n",
    "    \"V8\",\n",
    "    \"V15\",\n",
    "    \"V24\",\n",
    "    \"V35\",\n",
    "    \"T3\",\n",
    "    \"T8\",\n",
    "    \"T15\",\n",
    "    \"T24\",\n",
    "    \"T35\",\n",
    ")\n",
    "total_pdf = evolution.grid_values(pdf, evol_basis, xgrid, [Q0]).squeeze()[0]/xgrid\n",
    "print(total_pdf.shape)\n",
    "lumi = np.einsum('ij,kl->ikjl', total_pdf, total_pdf)\n",
    "lumi_masked = lumi[flavour_map]\n",
    "print(fktable.shape)\n",
    "print(lumi_masked.shape)\n",
    "res = np.einsum('ijkl,jkl->i', fktable, lumi_masked)\n",
    "#pd.concat([pd.DataFrame(res), cp, pd.DataFrame(res)/cp,  ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ff2522",
   "metadata": {},
   "outputs": [],
   "source": [
    "xfktable.reshape(48,91,-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4905c4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from validphys.fkparser import open_fkpath, _parse_string, _parse_header, _build_sigma\n",
    "from validphys.fkparser import _parse_flavour_map, _parse_hadronic_fast_kernel\n",
    "try:\n",
    "    f.close()\n",
    "except:\n",
    "    pass\n",
    "f = open_fkpath(old_fkspec.fkpath)\n",
    "line_and_stream = enumerate(f, start=1)\n",
    "lineno, header = next(line_and_stream)\n",
    "res = {}\n",
    "while True:\n",
    "    marker, header_name = _parse_header(lineno, header)\n",
    "    if header_name == \"FastKernel\":\n",
    "        break\n",
    "    if header_name == \"FlavourMap\":\n",
    "        out, lineno, header = _parse_flavour_map(line_and_stream)\n",
    "    else:\n",
    "        out, lineno, header = _parse_string(line_and_stream)\n",
    "    res[header_name] = out   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd41ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "res[\"FlavourMap\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d00059d",
   "metadata": {},
   "outputs": [],
   "source": [
    "i_hate_pandas = _parse_hadronic_fast_kernel(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde47252",
   "metadata": {},
   "outputs": [],
   "source": [
    "i_hate_pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7dcc9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_fktabledata.sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910dbb9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nnvortex",
   "language": "python",
   "name": "nnvortex"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
