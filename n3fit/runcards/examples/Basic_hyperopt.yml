#
# Configuration file for n3fit
#
############################################################
description:  Hyperopt example
############################################################
# frac: training fraction
# ewk: apply ewk k-factors
# sys: systematics treatment (see systypes)
dataset_inputs:
# Fixed target DIS
- {dataset: NMCPD_dw_ite, frac: 0.75}
- {dataset: NMC, frac: 0.75}
- {dataset: SLACP_dwsh, frac: 0.75}
- {dataset: SLACD_dw_ite, frac: 0.75}
- {dataset: BCDMSP_dwsh, frac: 0.75}
- {dataset: BCDMSD_dw_ite, frac: 0.75}
- {dataset: CHORUSNUPb_dw_ite, frac: 0.75}
- {dataset: CHORUSNBPb_dw_ite, frac: 0.75}
- {dataset: NTVNUDMNFe_dw_ite, frac: 0.75}
- {dataset: NTVNBDMNFe_dw_ite, frac: 0.75}
# HERA data
- {dataset: HERACOMBNCEM, frac: 0.75}
- {dataset: HERACOMBNCEP460, frac: 0.75}
- {dataset: HERACOMBNCEP575, frac: 0.75}
- {dataset: HERACOMBNCEP820, frac: 0.75}
- {dataset: HERACOMBNCEP920, frac: 0.75}
- {dataset: HERACOMBCCEM, frac: 0.75}
- {dataset: HERACOMBCCEP, frac: 0.75}


############################################################
datacuts:
  t0pdfset     : NNPDF40_nnlo_as_01180 # PDF set to generate t0 covmat
  q2min: 3.49                        # Q2 minimum
  w2min: 12.5                        # W2 minimum
  combocuts: NNPDF31                 # NNPDF3.0 final kin. cuts
  jetptcut_tev: 0                    # jet pt cut for tevatron
  jetptcut_lhc: 0                    # jet pt cut for lhc
  wptcut_lhc: 30.0                   # Minimum pT for W pT diff distributions
  jetycut_tev: 1e30                  # jet rap. cut for tevatron
  jetycut_lhc: 1e30                  # jet rap. cut for lhc
  dymasscut_min: 0                   # dy inv.mass. min cut
  dymasscut_max: 1e30                # dy inv.mass. max cut
  jetcfactcut: 1e30                  # jet cfact. cut

############################################################
theory:
  theoryid: 200        # database id

sampling:
  use_t0: false
  separate_multiplicative: true

hyperscan_config:
  stopping:
      min_epochs: 1e3
      max_epochs: 2e3
      min_patience: 0.10
      max_patience: 0.40
  positivity:
      min_multiplier: 1.01
      max_multiplier: 1.10
  optimizer:
    - optimizer_name: 'Adadelta'
      learning_rate:
        min: 0.008
        max: 0.07
    - optimizer_name: 'RMSprop'
      learning_rate:
        sampling: log
        min: 0.01
        max: 1.5
      clipnorm:
        max: 2.0
        min: 1.0
  architecture:
      initializers: ['glorot_normal', 'glorot_uniform']
      max_drop: 0.15
      n_layers: [2,3,4,5]
      min_units: 10
      max_units: 50
      activations: ['sigmoid', 'tanh']

kfold:
  target: average
  penalties:
    - saturation
    - patience
    - integrability
  threshold: 20.0
  partitions:
      - datasets:
          - HERACOMBCCEM
          - HERACOMBNCEP460
          - NMC
          - NTVNBDMNFe_dw_ite
      - datasets:
          - HERACOMBCCEP
          - HERACOMBNCEP575
          - NMCPD_dw_ite
          - NTVNUDMNFe_dw_ite
      - datasets:
          - CHORUSNBPb_dw_ite
          - HERACOMBNCEP820
          - BCDMSD_dw_ite
      - datasets:
          - CHORUSNUPb_dw_ite
          - HERACOMBNCEP920
          - BCDMSP_dwsh

############################################################
trvlseed: 1
nnseed: 2
mcseed: 3
genrep: false        # true = generate MC replicas, false = use real data

parameters: # This defines the parameter dictionary that is passed to the Model Trainer
  nodes_per_layer: [35, 25, 8]
  activation_per_layer: ['tanh', 'tanh', 'linear']
  initializer: 'glorot_normal'
  optimizer:
    learning_rate: 0.01
    optimizer_name: 'Adadelta'
  epochs: 40000
  positivity:
    multiplier: 1.09
    initial: 10.0
  stopping_patience: 0.30 # percentage of the number of epochs
  layer_type: 'dense'
  dropout: 0.0

fitting:
  # NN23(QED) = sng=0,g=1,v=2,t3=3,ds=4,sp=5,sm=6,(pht=7)
  # EVOL(QED) = sng=0,g=1,v=2,v3=3,v8=4,t3=5,t8=6,(pht=7)
  # EVOLS(QED)= sng=0,g=1,v=2,v8=4,t3=4,t8=5,ds=6,(pht=7)
  # FLVR(QED) = g=0, u=1, ubar=2, d=3, dbar=4, s=5, sbar=6, (pht=7)
  fitbasis: NN31IC # EVOL (7), EVOLQED (8), etc.
  basis:
      # remeber to change the name of PDF accordingly with fitbasis
      # smallx, largex: preprocessing ranges
      - { fl: sng,  trainable: False, smallx: [1.04,1.20], largex: [1.45,2.64] }
      - { fl: g,    trainable: False, smallx: [0.82,1.31], largex: [0.20,6.17] }
      - { fl: v,    trainable: False, smallx: [0.51,0.71], largex: [1.24,2.80] }
      - { fl: v3,   trainable: False, smallx: [0.23,0.63], largex: [1.02,3.14] }
      - { fl: v8,   trainable: False, smallx: [0.53,0.75], largex: [0.70,3.31] }
      - { fl: t3,   trainable: False, smallx: [-0.45,1.41], largex: [1.78,3.21] }
      - { fl: t8,   trainable: False, smallx: [0.49,1.32], largex: [1.42,3.13] }
      - { fl: cp,   trainable: False, smallx: [-0.07,1.13], largex: [1.73,7.37] }

############################################################
positivity:
  posdatasets:
  - {dataset: POSF2U, maxlambda: 1e6}        # Positivity Lagrange Multiplier
  - {dataset: POSF2DW, maxlambda: 1e6}
  - {dataset: POSF2S, maxlambda: 1e6}
  - {dataset: POSFLL, maxlambda: 1e6}
  - {dataset: POSDYU, maxlambda: 1e10}
  - {dataset: POSDYD, maxlambda: 1e10}
  - {dataset: POSDYS, maxlambda: 1e10}

############################################################
debug: false
