#
# Configuration file for n3fit
#
############################################################
description:  Hyperopt example
############################################################
# frac: training fraction
# ewk: apply ewk k-factors
# sys: systematics treatment (see systypes)
experiments:
# Fixed target DIS
- experiment: NMC
  datasets:
  - {dataset: NMCPD, frac: 0.5}
  - {dataset: NMC, frac: 0.5}
- experiment: SLAC
  datasets:
  - {dataset: SLACP, frac: 0.5}
  - {dataset: SLACD, frac: 0.5}
- experiment: BCDMS
  datasets:
  - {dataset: BCDMSP, frac: 0.5}
  - {dataset: BCDMSD, frac: 0.5}
- experiment: CHORUS
  datasets:
  - {dataset: CHORUSNUPb, frac: 0.5}
  - {dataset: CHORUSNBPb, frac: 0.5}
- experiment: NTVDMN
  datasets:
  - {dataset: NTVNUDMNFe, frac: 0.5}
  - {dataset: NTVNBDMNFe, frac: 0.5}
# HERA data
- experiment: HERACOMB
  datasets:
  - {dataset: HERACOMBNCEM, frac: 0.5}
  - {dataset: HERACOMBNCEP460, frac: 0.5}
  - {dataset: HERACOMBNCEP575, frac: 0.5}
  - {dataset: HERACOMBNCEP820, frac: 0.5}
  - {dataset: HERACOMBNCEP920, frac: 0.5}
  - {dataset: HERACOMBCCEM, frac: 0.5}
  - {dataset: HERACOMBCCEP, frac: 0.5}


############################################################
datacuts:
  t0pdfset     : NNPDF31_nnlo_as_0118 # PDF set to generate t0 covmat
  q2min: 3.49                        # Q2 minimum
  w2min: 12.5                        # W2 minimum
  combocuts: NNPDF31                 # NNPDF3.0 final kin. cuts
  jetptcut_tev: 0                    # jet pt cut for tevatron
  jetptcut_lhc: 0                    # jet pt cut for lhc
  wptcut_lhc: 30.0                   # Minimum pT for W pT diff distributions
  jetycut_tev: 1e30                  # jet rap. cut for tevatron
  jetycut_lhc: 1e30                  # jet rap. cut for lhc
  dymasscut_min: 0                   # dy inv.mass. min cut
  dymasscut_max: 1e30                # dy inv.mass. max cut
  jetcfactcut: 1e30                  # jet cfact. cut

############################################################
theory:
  theoryid: 53        # database id

hyperscan:
    stopping:
        min_epochs: 5e3
        max_epochs: 5e3
        min_patience: 0.10
        max_patience: 0.40
    positivity:
        min_multiplier: 1.01
        max_multiplier: 1.10
    optimizer:
      - optimizer_name: 'Adadelta'
        learning_rate:
          min: 0.008
          max: 0.07
      - optimizer_name: 'RMSprop'
        learning_rate:
          sampling: log
          min: 0.01
          max: 1.5
        clipnorm:
          max: 2.0
          min: 1.0
    architecture:
        initializers: ['glorot_normal', 'glorot_uniform']
        max_drop: 0.15
        n_layers: [2,3,4,5]
        min_units: 10
        max_units: 50
        activations: ['sigmoid', 'tanh']
    kfold: 
        penalties:
          - saturation
          - patience
        threshold: 2.0
        partitions:
            - datasets:
                - HERACOMBCCEM
                - HERACOMBNCEP460
                - NMC
                - NTVNBDMNFe
            - datasets:
                - HERACOMBCCEP
                - HERACOMBNCEP575
                - NMCPD
                - NTVNUDMNFe
            - datasets:
                - CHORUSNBPb
                - HERACOMBNCEP820
                - BCDMSD
            - datasets:
                - CHORUSNUPb
                - HERACOMBNCEP920
                - BCDMSP

############################################################
fitting:
  trvlseed: 1
  nnseed: 2
  mcseed: 3
  seed: 9453862133528           # set the seed for the random generator
  genrep: off        # on = generate MC replicas, off = use real data
  rngalgo: 0        # 0 = ranlux, 1 = cmrg, see randomgenerator.cc
  fitmethod: NGA    # Minimization algorithm
  ngen: 30000       # Maximum number of generations
  nmutants: 80      # Number of mutants for replica
  paramtype: NN
  nnodes: [2, 5, 3, 1]

  parameters: # This defines the parameter dictionary that is passed to the Model Trainer
    nodes_per_layer: [35, 25, 8]
    activation_per_layer: ['tanh', 'tanh', 'linear']
    initializer: 'glorot_normal'
    optimizer:
      learning_rate: 0.01
      optimizer_name: 'Adadelta'
    epochs: 40000
    positivity:
      multiplier: 1.09
      initial: 10.0
    stopping_patience: 0.30 # percentage of the number of epochs
    layer_type: 'dense'
    dropout: 0.0



  # NN23(QED) = sng=0,g=1,v=2,t3=3,ds=4,sp=5,sm=6,(pht=7)
  # EVOL(QED) = sng=0,g=1,v=2,v3=3,v8=4,t3=5,t8=6,(pht=7)
  # EVOLS(QED)= sng=0,g=1,v=2,v8=4,t3=4,t8=5,ds=6,(pht=7)
  # FLVR(QED) = g=0, u=1, ubar=2, d=3, dbar=4, s=5, sbar=6, (pht=7)
  fitbasis: NN31IC # EVOL (7), EVOLQED (8), etc.
  basis:
      # remeber to change the name of PDF accordingly with fitbasis
      # pos: on for NN squared
      # mutsize: mutation size
      # mutprob: mutation probability
      # smallx, largex: preprocessing ranges
      - { fl: sng, pos: False, mutsize: [15], trainable: False, mutprob: [0.05], smallx: [1.04,1.20], largex: [1.45,2.64] }
      - { fl: g,   pos: False, mutsize: [15], trainable: False, mutprob: [0.05], smallx: [0.82,1.31], largex: [0.20,6.17] }
      - { fl: v,   pos: False, mutsize: [15], trainable: False, mutprob: [0.05], smallx: [0.51,0.71], largex: [1.24,2.80] }
      - { fl: v3,  pos: False, mutsize: [15], trainable: False, mutprob: [0.05], smallx: [0.23,0.63], largex: [1.02,3.14] }
      - { fl: v8,  pos: False, mutsize: [15], trainable: False, mutprob: [0.05], smallx: [0.53,0.75], largex: [0.70,3.31] }
      - { fl: t3,  pos: False, mutsize: [15], trainable: False, mutprob: [0.05], smallx: [-0.45,1.41], largex: [1.78,3.21] }
      - { fl: t8,  pos: False, mutsize: [15], trainable: False, mutprob: [0.05], smallx: [0.49,1.32], largex: [1.42,3.13] }
      - { fl: cp,  pos: False, mutsize: [15], trainable: False, mutprob: [0.05], smallx: [-0.07,1.13], largex: [1.73,7.37] }

############################################################
stopping:
  stopmethod: LOOKBACK  # Stopping method
  lbdelta: 0            # Delta for look-back stopping
  mingen: 0             # Minimum number of generations
  window: 500           # Window for moving average
  minchi2: 3.5          # Minimum chi2 
  minchi2exp: 6.0       # Minimum chi2 for experiments
  nsmear: 200           # Smear for stopping
  deltasm: 200          # Delta smear for stopping
  rv: 2                 # Ratio for validation stopping
  rt: 0.5               # Ratio for training stopping
  epsilon: 1e-6         # Gradient epsilon

############################################################
positivity:
  posdatasets:
  - {dataset: POSF2U, poslambda: 1e6}        # Positivity Lagrange Multiplier
  - {dataset: POSF2DW, poslambda: 1e6}
  - {dataset: POSF2S, poslambda: 1e6}
  - {dataset: POSFLL, poslambda: 1e6}
  - {dataset: POSDYU, poslambda: 1e10}
  - {dataset: POSDYD, poslambda: 1e10}
  - {dataset: POSDYS, poslambda: 1e10}

############################################################
closuretest:
  filterseed: 0     # Random seed to be used in filtering data partitions
  fakedata: off     # on = to use FAKEPDF to generate pseudo-data
  fakepdf: MSTW2008nlo68cl      # Theory input for pseudo-data
  errorsize: 1.0    # uncertainties rescaling
  fakenoise: off    # on = to add random fluctuations to pseudo-data
  rancutprob: 1.0   # Fraction of data to be included in the fit
  rancutmethod: 0   # Method to select rancutprob data fraction
  rancuttrnval: off # 0(1) to output training(valiation) chi2 in report
  printpdf4gen: off # To print info on PDFs during minimization

############################################################
lhagrid:
  nx: 150
  xmin: 1e-9
  xmed: 0.1
  xmax: 1.0
  nq: 50
  qmax: 1e5

############################################################
debug: off
